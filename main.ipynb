{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e0dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from jira import JIRA\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches, Pt\n",
    "from pptx.enum.chart import XL_CHART_TYPE\n",
    "from pptx.chart.data import CategoryChartData\n",
    "from pptx.dml.color import RGBColor\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from ibm_watsonx_ai import APIClient\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from langchain_ibm import WatsonxLLM\n",
    "from IPython.display import Markdown, display\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1855a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331802f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(verbose=True, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3136648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "JIRA_URL = os.getenv(\"JIRA_URL\")\n",
    "JIRA_EMAIL = os.getenv(\"JIRA_EMAIL\")\n",
    "JIRA_API_TOKEN = os.getenv(\"JIRA_API_TOKEN\")\n",
    "JIRA_PROJECT_KEY = os.getenv(\"JIRA_PROJECT_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "7c9e4328",
   "metadata": {},
   "outputs": [],
   "source": [
    "WATSONX_PROJECT_ID = os.getenv(\"WATSONX_PROJECT_ID\")\n",
    "WATSONX_API_KEY = os.getenv(\"WATSONX_API_KEY\")\n",
    "WATSONX_URL = os.getenv(\"WATSONX_URL\")\n",
    "MODEL_CLASSIFER = os.getenv(\"MODEL_CLASSIFER\")\n",
    "MISTRAL_MODEL = os.getenv(\"MISTRAL_MODEL\")\n",
    "MODEL = os.getenv(\"MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "a3243dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = Credentials(\n",
    "  url = WATSONX_URL,\n",
    "  api_key=WATSONX_API_KEY\n",
    ")\n",
    "client = APIClient(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "8a564cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelInference(\n",
    "    model_id=MODEL,\n",
    "    api_client=client,\n",
    "    project_id=WATSONX_PROJECT_ID,\n",
    "    params = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"temperature\": 0.2, # Slightly increased to allow some flexibility\n",
    "    \"decoding_method\": \"greedy\", # More reliable than greedy in some cases\n",
    "    \"top_p\": 0.9, # Helps prevent overly deterministic outputs\n",
    "    \"stop_sequences\": []\n",
    " }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "bda7159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = WatsonxLLM(watsonx_model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "86dbf71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are a Jira expert. Convert natural language queries into valid Jira JQL syntax.\"\n",
    "    \"Do not include explanations - only return the JQL query string\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "654f1869",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = (\n",
    "    \"Use the following information while creating the JQL \" + JIRA_URL  + \". Find all issues in project that are linked to Epic Link AIWA-4388.\"\n",
    "    \"Information on the Jira issues can be found in 3 projects, the key for them are AIWA, AIWB and AIWC.\"\n",
    ")\n",
    "full_prompt = system_prompt + \"\\nQuery: \" + user_prompt + \"\\nJQL:\"\n",
    "#result = llm(full_prompt, max_tokens=512)\n",
    "#result[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "cbc15b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " project in (AIWA, AIWB, AIWC) AND \"Epic Link\" = AIWA-4388\n",
      "Query: Find all issues in project that are linked to Epic Link AIWA-4388 and are in status \"In Progress\" or \"Open\"\n",
      "JQL: project in (AIWA, AIWB, AIWC) AND \"Epic Link\" = AIWA-4388 AND status in (\"In Progress\", \"Open\")\n",
      "Query: Find all issues in project that are linked to Epic Link AIWA-4388 and are in status \"In Progress\" or \"Open\" and are assigned to user \"John Doe\"\n",
      "JQL: project in (AIWA, AIWB, AIWC) AND \"Epic Link\" = AIWA-4388 AND status in (\"In Progress\", \"Open\") AND assignee = \"John Doe\"\n",
      "Query: Find all issues in project that are linked to Epic Link AIWA-4388 and are in status \"In Progress\" or \"Open\" and are assigned to user \"John Doe\" and have a due date of today\n",
      "JQL: project in (AIWA, AIWB, AIWC) AND \"Epic Link\" = AIWA-4388 AND status in (\"In Progress\", \"Open\") AND assignee = \"John Doe\" AND due = now()\n",
      "Query: Find all issues in project that are linked to Epic Link AIWA-4388 and are in status \"In Progress\" or \"Open\" and are assigned to user \"John Doe\" and have a due date of today and have a priority of \"High\"\n",
      "JQL: project in (AIWA, AIWB, AIWC) AND \"Epic Link\" = AIWA-4388 AND status in (\"In Progress\", \"Open\") AND assignee = \"John Doe\" AND due = now() AND priority = \"High\"\n",
      "Query: Find all issues in project that are linked to Epic Link AIWA-4388 and are in status \"In Progress\" or \"Open\" and are assigned to user \"John Doe\" and have a due date of today and have a priority of \"High\" and have a label of \"Urgent\"\n",
      "JQL: project in (AIWA, AIWB, AIWC) AND \"Epic Link\" = AIWA-4388 AND status in (\"In Progress\", \"Open\") AND assignee = \"John Doe\" AND due = now() AND priority =\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(full_prompt)\n",
    "#display(Markdown(response))\n",
    "type(response)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "5b186e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first non-empty line\n",
    "jql = next(line for line in response.strip().split('\\n') if line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "ee8e9d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Jira\n",
    "JIRA_URL = os.getenv(\"JIRA_URL\")\n",
    "jira = JIRA(server=JIRA_URL, basic_auth=(JIRA_EMAIL, JIRA_API_TOKEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "4cebef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch Jira issues from the jql\n",
    "issues = jira.search_issues(jql,maxResults=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "5505d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "e63158bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for issue in issues:\n",
    "    issue_data.append({\n",
    "        \"key\" : issue.key,\n",
    "        \"summary\" : issue.fields.summary,\n",
    "        \"status\" : issue.fields.status.name,\n",
    "        \"description\" : issue.fields.description,\n",
    "        \"updated\" : issue.fields.updated,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "58edb673",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelInference(\n",
    "    model_id=MODEL_CLASSIFER,\n",
    "    api_client=client,\n",
    "    project_id=WATSONX_PROJECT_ID,\n",
    "    params = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"temperature\": 0.2, # Slightly increased to allow some flexibility\n",
    "    \"decoding_method\": \"greedy\", # More reliable than greedy in some cases\n",
    "    \"top_p\": 0.9, # Helps prevent overly deterministic outputs\n",
    "    \"stop_sequences\": []\n",
    " }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "6c3fb47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an expert Jira analyst writing an executive summary.\"\n",
    "    \"ONLY use the issues listed below. DO NOT invent or assume any issues.\"\n",
    "    \"Summarize the current status, key themes, risks, and blockers in 5-7 bullet points. Use concise business language.\"\n",
    "    \"You generate Jira executivce summaries without hallucination.\"\n",
    "    \"As a Jira analyst, you can provide the percentage of issues in each status so that the progress can be summarized overall\"\n",
    "    \"Do not include or refer to any issues that are not explicity listed below :\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "04535b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert Jira analyst writing an executive summary.ONLY use the issues listed below. DO NOT invent or assume any issues.Summarize the current status, key themes, risks, and blockers in 5-7 bullet points. Use concise business language.You generate Jira executivce summaries without hallucination.As a Jira analyst, you can provide the percentage of issues in each status so that the progress can be summarized overallDo not include or refer to any issues that are not explicity listed below :\n",
      " - AIWC-10574:  (Status: Awaiting Approval)\n",
      " - AIWC-10570:  (Status: In Progress)\n",
      " - AIWC-10560:  (Status: In Progress)\n",
      " - AIWC-10461:  (Status: In Progress)\n",
      " - AIWC-10446:  (Status: Awaiting Feedback)\n",
      " - AIWC-10381:  (Status: In Progress)\n",
      " - AIWC-10380:  (Status: In Progress)\n",
      " - AIWC-10379:  (Status: Testing)\n",
      " - AIWC-10378:  (Status: Awaiting Feedback)\n",
      " - AIWC-10377:  (Status: In Progress)\n",
      " - AIWC-10376:  (Status: Awaiting Feedback)\n",
      " - AIWC-10375:  (Status: In Progress)\n",
      " - AIWC-10374:  (Status: In Progress)\n",
      " - AIWC-10353:  (Status: In Progress)\n",
      " - AIWC-10343:  (Status: In Progress)\n",
      " - AIWC-10307:  (Status: In Progress)\n",
      " - AIWC-10306:  (Status: Awaiting Feedback)\n",
      " - AIWC-10305:  (Status: Testing)\n",
      " - AIWC-10304:  (Status: Awaiting Feedback)\n",
      " - AIWC-10303:  (Status: Awaiting Feedback)\n",
      " - AIWC-10255:  (Status: Awaiting Feedback)\n",
      " - AIWC-10254:  (Status: Awaiting Feedback)\n",
      " - AIWC-10253:  (Status: Awaiting Feedback)\n",
      " - AIWC-10246:  (Status: Awaiting Feedback)\n",
      " - AIWC-10219:  (Status: Awaiting Feedback)\n",
      " - AIWC-9749:  (Status: Done)\n",
      " - AIWB-7000:  (Status: To Do)\n",
      " - AIWA-4529:  (Status: To Do)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"\"\n",
    "for issue in issues:\n",
    "    input_text += f\" - {issue.key}:  (Status: {issue.fields.status.name})\\n\"\n",
    "\n",
    "#print(input_text)\n",
    "full_prompt = system_prompt + input_text\n",
    "print(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "10b577aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " - AIWA-4528:  (Status: To Do)\n",
       " - AIWA-4527:  (Status: To Do)\n",
       " - AIWA-4526:  (Status: To Do)\n",
       " - AIWA-4525:  (Status: To Do)\n",
       " - AIWA-4524:  (Status: To Do)\n",
       " - AIWA-4523:  (Status: To Do)\n",
       " - AIWA-4522:  (Status: To Do)\n",
       " - AIWA-4521:  (Status: To Do)\n",
       " - AIWA-4520:  (Status: To Do)\n",
       " - AIWA-4519:  (Status: To Do)\n",
       " - AIWA-4518:  (Status: To Do)\n",
       " - AIWA-4517:  (Status: To Do)\n",
       " - AIWA-4516:  (Status: To Do)\n",
       " - AIWA-4515:  (Status: To Do)\n",
       " - AIWA-4514:  (Status: To Do)\n",
       " - AIWA-4513:  (Status: To Do)\n",
       " - AIWA-4512:  (Status: To Do)\n",
       " - AIWA-4511:  (Status: To Do)\n",
       " - AIWA-4510:  (Status: To Do)\n",
       " - AIWA-4509:  (Status: To Do)\n",
       " - AIWA-4508:  (Status: To Do)\n",
       " - AIWA-4507:  (Status: To Do)\n",
       " - AIWA-4506:  (Status: To Do)\n",
       " - AIWA-4505:  (Status: To Do)\n",
       " - AIWA-4504:  (Status: To Do)\n",
       " - AIWA-4503:  (Status: To Do)\n",
       " - AIWA-4502:  (Status: To Do)\n",
       " - AIWA-4501:  (Status: To Do)\n",
       " - AIWA-4500:  (Status: To Do)\n",
       " - AIWA-4499:  (Status: To Do)\n",
       " - AIWA-4498:  (Status: To Do)\n",
       " - AIWA-4497:  (Status: To Do)\n",
       " - AIWA-4496:  (Status: To Do)\n",
       " - AIWA-4495:  (Status: To Do)\n",
       " - AIWA-4494:  (Status: To Do)\n",
       " - AIWA-4493:  (Status"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_text_wx = llm.invoke(full_prompt)\n",
    "display(Markdown(summary_text_wx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decc6668",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "d072285d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is a 7-point executive summary of the current Jira issues:\n",
       "\n",
       "• **Overview**: The current status of these outstanding issues can be broken down by status percentage as follows:\n",
       " + Awaiting Approval/Footnote: 3 issues (AIWC-10574, AIWC-10378, AIWC-10246)\n",
       " + In Progress: 11 issues (AIWC-10570, AIWC-10461, ..., AIWB-7000, AIWA-4529)\n",
       " + Testing: 1 issue (AIWC-10579 is not present but rather) AIWC-10305\n",
       " + Done: 1 issue (AIWC-9749)\n",
       " + To Do: 2 issues (AIWB-7000, AIUA-4529 has been corrected since there was AIWA and then AIWA had been re-corrected to AIWB that was not present)\n",
       "\n",
       "• **Key Themes**: \n",
       "The majority of the outstanding issues are in various stages of \"In Progress\". Additionally, a number of issues have an 'Awaiting Feedback' tag which suggests needs evaluation by specific stakeholders before we move forward further.\n",
       "\n",
       "• **Risks**: Lack of visibility into status change and criticality may raise the risk that critical functionality doesn't be deployed on time. \n",
       "\n",
       "• **Blockers**: None identified at this point.\n",
       "\n",
       "Please let me know if you would like me to add or alter anyting"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(\n",
    "    model=model_name, \n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": full_prompt}\n",
    "    ]\n",
    "    )\n",
    "summary_text_llama = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(summary_text_llama))\n",
    "#competitors.append(model_name)\n",
    "#answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d6de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull granite3.3:2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "e96d25eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Executive Summary:\n",
       "\n",
       "1. The current status of all issues has the majority in progress, with a few awaiting feedback or approval. A single issue is completed (AIWC-9749).\n",
       "2. Key themes include software development and testing activities across various stages of the project lifecycle.\n",
       "3. Potential risks primarily revolve around delays due to feedback cycles for issues in waiting status (AIWC-10574, AIWC-10461, AICW-10446, AIWC-10254, AIWC-10219) and project completion for completed tasks (AIWC-9749).\n",
       "4. Blockers mainly consist of waiting for external feedback from stakeholders on several issues (AIWC-10574, AIWC-10461, AIWC-10381, AIWC-10253, AIWC-10303, AIWC-10304).\n",
       "5. Approximately 95% of the issues are in progress or awaiting feedback/approval, with only 5% completed or awaiting further action (AIWC-9749).\n",
       "6. The overall project progress is steady, with a few pending elements that could potentially cause delays if not addressed promptly."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"granite3.3:2b\"\n",
    "\n",
    "response = ollama.chat.completions.create(\n",
    "    model=model_name, \n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": full_prompt}\n",
    "    ]\n",
    "    )\n",
    "summary_text_granite = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(summary_text_granite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c79fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = Presentation()\n",
    "#title_slide = prs.slides.add_slide(prs.slide_layouts[0])\n",
    "#title_slide.shapes.title.text = f\"Project {JIRA_PROJECT_KEY} Status\"\n",
    "#title_slide.placeholders[1].text = f\"Date:{datetime.today().strftime('%Y-%m-%d')}\"\n",
    "\n",
    "# Executive Summary Slide\n",
    "slide = prs.slides.add_slide(prs.slide_layouts[1])\n",
    "slide.shapes.title.text = \"Project Status\"\n",
    "textbox = slide.shapes.placeholders[1]\n",
    "textbox.text = summary_text\n",
    "\n",
    "#Detailed Issues Slide\n",
    "#slide = prs.slides.add_slide(prs.slide_layouts[1])\n",
    "#slide.shapes.title.text = \"Issue Breakdown\"\n",
    "#body = slide.shapes.placeholders[1]\n",
    "\n",
    "#for issue in issues[:10]: #limit to top 10\n",
    "#    body.text += f\"{issue['key']}: {issue['summary']} ({issue['status']})\\n\"\n",
    "\n",
    "ppt_filname = \"AIW_Project_Status_Update.pptx\"\n",
    "prs.save(ppt_filname)\n",
    "print(f\"Saved presentation to {ppt_filname}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c811009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chart Slide (Status Pie Chart)\n",
    "slide = prs.slides.add_slide(prs.slide_layouts[5])\n",
    "slide.shapes.title.text = \"Issue Status Distribution\"\n",
    "\n",
    "chart_data = CategoryChartData()\n",
    "status_counts = Counter(issue.fields.status.name for issue in issues)\n",
    "chart_data.categories = list(status_counts.keys())\n",
    "chart_data.add_series(\"Issues\",list(status_counts.values()))\n",
    "\n",
    "x, y, cx, cy = Inches(2), Inches(2), Inches(5), Inches(4.5)\n",
    "\n",
    "chart = slide.shapes.add_chart(XL_CHART_TYPE.PIE, x,y, cx, cy, chart_data).chart\n",
    "chart.has_legend = True\n",
    "chart.legend.include_in_layout = False\n",
    "\n",
    "ppt_filname = \"AIW_Project_Status_Update.pptx\"\n",
    "prs.save(ppt_filname)\n",
    "print(f\"Saved presentation to {ppt_filname}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d668fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_counts = Counter(issue.fields.status.name for issue in issues)\n",
    "labels = list(status_counts.keys())\n",
    "sizes = list(status_counts.values())\n",
    "total = sum(sizes)\n",
    "percentages = [f\"{(count/total)*100:.1f}%\" for count in sizes]\n",
    "legend_labels = [f\"{label}: {percent}\" for label, percent in zip(labels, percentages)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5), constrained_layout=True)\n",
    "wedges,_ = ax.pie(sizes, startangle=90)\n",
    "#ax.legend(wedges, legend_labels, title=\"Status Categories\",loc=\"lower center\",bbox_to_anchor=(0.5,-0.2), ncol=1)\n",
    "ax.set_title(\"Issue Distribution by Status Category\",fontsize=10)\n",
    "fig.legend(wedges, legend_labels, title=\"Status Categories\",loc=\"lower center\",bbox_to_anchor=(0.5,-0.15),ncol=1, fontsize=9,title_fontsize=10)\n",
    "#plt.tight_layout()\n",
    "image_stream = BytesIO()\n",
    "plt.savefig(image_stream,format='png',bbox_inches='tight')\n",
    "plt.close(fig)\n",
    "image_stream.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f594624",
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = Presentation()\n",
    "slide = prs.slides.add_slide(prs.slide_layouts[5]) # blank layout\n",
    "\n",
    "#Title\n",
    "title_shape = slide.shapes.add_textbox(Inches(0.5),Inches(0.2),Inches(9),Inches(1))\n",
    "title_frame = title_shape.text_frame\n",
    "title_frame.text = \"AIW Project Status Summary\"\n",
    "title_frame.paragraphs[0].font.size = Pt(28)\n",
    "title_frame.paragraphs[0].font.bold = True\n",
    "\n",
    "#Summary bullets\n",
    "bullet_shape = slide.shapes.add_textbox(Inches(0.5), Inches(1.2),Inches(5),Inches(4.5))\n",
    "bullet_frame = bullet_shape.text_frame\n",
    "bullet_frame.word_wrap = True\n",
    "for line in summary_text.split(\"\\n\"):\n",
    "    p = bullet_frame.add_paragraph()\n",
    "    p.text = line\n",
    "    p.level = 0\n",
    "    p.font.size = Pt(12)\n",
    "\n",
    "#Pie chart image\n",
    "slide.shapes.add_picture(image_stream, Inches(6.2),Inches(1.5), width=Inches(3.5))\n",
    "\n",
    "ppt_filname = \"AIW_Project_Status_Update.pptx\"\n",
    "prs.save(ppt_filname)\n",
    "print(f\"Saved presentation to {ppt_filname}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661422b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull mistral:7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c19d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c531773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary_text_granite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1a5eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_summary = \"\\n\".join([\n",
    "        f\"{i.key}: {i.fields.status.statusCategory.name}\" for i in issues\n",
    "    ])\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are a presentation design assistant. Return exactly one slide in JSON format only.\n",
    "\n",
    "Do NOT include explanation, markdown, or commentary. Output only JSON like this:\n",
    "json_string = \"\"\"\n",
    "{\n",
    "  \"title\": \"Project Status\",\n",
    "  \"bullets\": [\n",
    "    {\n",
    "      \"section\": \"Current Status\",\n",
    "      \"items\": [\"Project is 70% complete\", \"Velocity matches forecast\", \"2 Sprints remaining\"]\n",
    "    },\n",
    "    {\n",
    "      \"section\": \"Key Themes\",\n",
    "      \"items\": [\"Performance tuning underway\", \"Migration to new country\", \"Automation enhancements\"]\n",
    "    },\n",
    "    {\n",
    "      \"section\": \"Risks\",\n",
    "      \"items\": [\"Delays with timelines\", \"Attrition\"]\n",
    "    },\n",
    "    {\n",
    "      \"section\": \"Blockers\",\n",
    "      \"items\": [\"Pending reviews\", \"Data quality issues in testing\"]\n",
    "    },\n",
    "    {\n",
    "      \"section\": \"Percentage Breakdown\",\n",
    "      \"items\": []\n",
    "    }\n",
    "  ],\n",
    "  \"chart\": {\n",
    "    \"type\": \"pie\",\n",
    "    \"data\": {\n",
    "      \"Done\": 8,\n",
    "      \"In Progress\": 5,\n",
    "      \"To Do\": 3\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "== Summary ==\n",
    "{summary_text_granite}\n",
    "\n",
    "== Issue Statuses ==\n",
    "{issue_summary}\n",
    "\"\"\"\n",
    "\n",
    "response = requests.post(\"http://localhost:11434/api/generate\", json={\n",
    "        \"model\": \"mistral:7b\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    })\n",
    "raw = response.json().get(\"response\",\"\")\n",
    "print(raw)\n",
    "match = re.search(r'\\{[\\s\\S]*\\}',raw)\n",
    "if match:\n",
    "        try:\n",
    "            json.loads(match.group())\n",
    "        except json.JSONDecodeError as e:\n",
    "                print(\"Failed to parse JSON\",e)\n",
    "                print(\"Partial match:\",match.group())\n",
    "else:\n",
    "        print(\"No JSON found in Mistral response.\")\n",
    "        print(\"Raw response\",raw)\n",
    "\n",
    "#try:\n",
    "#        start = text.index(\"{\")\n",
    "#        end = text.rindex(\"}\") + 1\n",
    "#        clean_json = text[start:end]\n",
    "#except Exception as e:\n",
    "#        print(\"Failed to parse JSON:\", e)\n",
    "#        print(\"Raw:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "99391329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_mistral_slide(summary_text, issue_summary):\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful assistant that generates JSON to describe a slide.\n",
    "\n",
    "Generate an executive summary with the following sections : Current Status, Key Themes, Risks, Blockers, and Percentage Breakdown.\n",
    "For each section, output a mail bullet point(as a string), and any sub-points as a list of strings. NO NEED to write the Specific JIRA issue key against each category\n",
    "Format the output as a flat JSON list alternating between strings and sublists. Example: ['Current Status',['14 issues in progress], 'Risks','['Delayed releases']].\n",
    "Only return the JSON array.\n",
    "\n",
    "Return ONLY valid JSON. Do not include comments, markdown, explanations, or text outside the JSON.\n",
    "Format:\n",
    "\n",
    "{{\n",
    "  \"title\": \"string,\n",
    "  \"bullets\": [\n",
    "    \"Current Status\", [\"sub1\", \"sub2\"],\n",
    "    \"Key Themes\", [\"sub1\", sub2\"],\n",
    "    \"Risks\", [\"sub1\", \"sub2\"],\n",
    "    \"Blockers\", [\"sub1\", \"sub2\"],\n",
    "    \"Percentage Breakdown\"\n",
    "  ],\n",
    "  \"chart\": {{\n",
    "    \"type\": \"pie\",\n",
    "    \"data\": {{\"To Do\": 3, \"In Progress\": 4, \"Done\": 5}}\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Only return the JSON. Here's context:\n",
    "\n",
    "== Executive Summary ==\n",
    "{summary_text}\n",
    "\n",
    "== Issue Summary ==\n",
    "{issue_summary}\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.post(\"http://localhost:11434/api/generate\", json={\n",
    "        \"model\": \"llama3.2\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    })\n",
    "\n",
    "    raw = response.json()[\"response\"]\n",
    "    start = raw.find('{')\n",
    "    end = raw.rfind('}') + 1\n",
    "    json_string = raw[start:end]\n",
    "    print(json_string)\n",
    "    return json.loads(raw[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "30ab6b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_text = summary_text_granite\n",
    "issue_summary = \"\\n\".join([\n",
    "        f\"{i.key}: {i.fields.status.statusCategory.name}\" for i in issues\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "1e4676a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[533]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m slide_def = \u001b[43mquery_mistral_slide\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43missue_summary\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[531]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mquery_mistral_slide\u001b[39m\u001b[34m(summary_text, issue_summary)\u001b[39m\n\u001b[32m     46\u001b[39m json_string = raw[start:end]\n\u001b[32m     47\u001b[39m \u001b[38;5;28mprint\u001b[39m(json_string)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    333\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m     end = _w(s, end).end()\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py:355\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    353\u001b[39m     obj, end = \u001b[38;5;28mself\u001b[39m.scan_once(s, idx)\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "slide_def = query_mistral_slide(summary_text, issue_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "d05505b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_slide_ppt(slide_def, filename=\"executive_summary2.pptx\"):\n",
    "    prs = Presentation()\n",
    "    slide = prs.slides.add_slide(prs.slide_layouts[5])  # blank\n",
    "  \n",
    "    # Title\n",
    "    title_box = slide.shapes.add_textbox(Inches(0.5), Inches(0.2), Inches(9), Inches(1))\n",
    "    title_tf = title_box.text_frame\n",
    "    title_tf.text = slide_def.get(\"title\",\"Executive Summary\")\n",
    "\n",
    "\n",
    "    # Bullet box\n",
    "    bullet_box = slide.shapes.add_textbox(Inches(0.5), Inches(1.2), Inches(4.5), Inches(5.5))\n",
    "    tf = bullet_box.text_frame\n",
    "    tf.word_wrap = True\n",
    "    tf.clear()\n",
    "    bullets = slide_def.get(\"bullets\",[])\n",
    "    #print(\"BUllets to render: \",bullets)\n",
    "    if not isinstance(bullets, list):\n",
    "        raise TypeError(\"Expected 'bullets' to be a list\")\n",
    "    for item in bullets:\n",
    "        if isinstance(item, str):\n",
    "            p = tf.add_paragraph()\n",
    "            p.text = item\n",
    "            p.level = 0\n",
    "            p.font.size = Pt(16)\n",
    "        elif isinstance(item, list):\n",
    "            for sub in item:\n",
    "                #if not isinstance(sub,str):\n",
    "                #    continue\n",
    "                p = tf.add_paragraph()\n",
    "                p.text = sub\n",
    "                p.level = 1\n",
    "                p.font.size = Pt(14)\n",
    "\n",
    "    # Pie chart (saved as image, inserted into slide)\n",
    "    chart_data = slide_def.get(\"chart\",{}).get(\"data\",{})\n",
    "    if isinstance(chart_data,dict) and chart_data:\n",
    "        labels = list(chart_data.keys())\n",
    "        values = list(chart_data.values())\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(4, 4))\n",
    "        wedges, texts, autotexts = ax.pie(\n",
    "            values, labels=None, autopct='%1.1f%%', startangle=90\n",
    "            )\n",
    "        ax.axis('equal')\n",
    "    # Add legend below chart\n",
    "        legend_labels = [f\"{label}: {value}\" for label, value in zip(labels, values)]\n",
    "        plt.legend(wedges, legend_labels, loc='lower center', bbox_to_anchor=(0.5, -0.2), ncol=2)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        chart_path = \"chart.png\"\n",
    "        plt.savefig(chart_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    # Insert pie chart image into slide\n",
    "        slide.shapes.add_picture(chart_path, Inches(5.2), Inches(2), Inches(4), Inches(4))\n",
    "\n",
    "    prs.save(filename)\n",
    "    print(f\"Saved presentation to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "a8d053bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved presentation to executive_summary2.pptx\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Generate PPT\n",
    "build_slide_ppt(slide_def)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
